{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOb+52Rt5+4KPVokakFX8m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RogShotz/CSC-482-Project/blob/model-testing/CSC482_Project_Geneology_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Geneology Extractor**\n",
        "\n",
        "---\n",
        "\n",
        "Here we go I guess. Here's some wiki stuff for extracting articles."
      ],
      "metadata": {
        "id": "QMQQKY_UAQH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgbtKSGGDU11",
        "outputId": "d29784f8-f2ad-4b48-ab73-09d6fa9bf2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example data (replace with your dataset)\n",
        "texts = [\"John Fitzgerald Kennedy was born outside Boston in Brookline, Massachusetts, on May 29, 1917, at 83 Beals Street, to Joseph P. Kennedy Sr., a businessman and politician, and Rose Kennedy, a philanthropist and socialite.\",\n",
        "         \"John Fitzgerald Kennedy was born outside Boston in Brookline, Massachusetts, on May 29, 1917, at 83 Beals Street, to Joseph P. Kennedy Sr., a businessman and politician, and Rose Kennedy, a philanthropist and socialite.\",\n",
        "         \"All four of his grandparents were children of Irish immigrants. His paternal grandfather, P. J. Kennedy, served as a Massachusetts state legislator.\",\n",
        "         \"Kennedy's maternal grandfather and namesake, John F. Fitzgerald, served as a U.S. Congressman and was elected to two terms as Mayor of Boston.\",\n",
        "         \"Kennedy had an older brother, Joseph Jr., and seven younger siblings: Rosemary, Kathleen, Eunice, Patricia, Robert, Jean, and Edward.\"]\n",
        "\n",
        "labels = [\"father\", \"mother\", \"grandson\", \"grandson\", \"sibling\"]\n",
        "\n",
        "# Tokenize and preprocess text data\n",
        "def preprocess_text(text):\n",
        "    words = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
        "    words = [word for word in words if word.isalnum()]  # Remove non-alphanumeric characters\n",
        "    words = [word for word in words if word not in stopwords.words('english')]  # Remove stopwords\n",
        "    return dict([(word, True) for word in words])\n"
      ],
      "metadata": {
        "id": "MSDItSMdEKpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the labeled data in the required format for NLTK\n",
        "featuresets = [(preprocess_text(text), label) for text, label in zip(texts, labels)]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_set, test_set = train_test_split(featuresets, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "nb_classifier = NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "for text_features, _ in test_set:\n",
        "    prob_dist = nb_classifier.prob_classify(text_features)\n",
        "    print(f\"Text: {' '.join(text_features.keys())}\")\n",
        "    print(f\"Probability of having 'son' relation: {prob_dist.prob('son')}\")\n",
        "    print(f\"Probability of not having 'son' relation: {prob_dist.prob('not_son')}\")\n",
        "    print(\"------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n1JbjQCEX_u",
        "outputId": "6b07050c-584b-45d6-c0e1-1e93664f9798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: four grandparents children irish immigrants paternal grandfather kennedy served massachusetts state legislator\n",
            "Probability of having 'son' relation: 0.2307692307692308\n",
            "Probability of not having 'son' relation: 0\n",
            "------\n"
          ]
        }
      ]
    }
  ]
}